{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import random\n",
    "import html2text\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as exp_cond\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "print('Modules loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def queryString(param):\n",
    "    return re.sub('[^A-z0-9 ]', '', param).lower().replace(\" \", \"+\").replace(\"_\", \"+\")\n",
    "\n",
    "def getCleanData(param):\n",
    "    result = removeSpecialCharacters(param)\n",
    "    result = removeStopWords(result)\n",
    "    return result.lower()\n",
    "\n",
    "def removeSpecialCharacters(param):\n",
    "    result = param.replace(\"-\", \" \")\n",
    "    result = re.sub('[^A-z0-9 ]', ' ', result)\n",
    "    result = ' '.join(result.split())\n",
    "    return result.lower()\n",
    "\n",
    "def addSpaceBeforeParentheses(param):\n",
    "    return re.sub('\\(+', ' (', param).replace('  ', ' ')\n",
    "\n",
    "def getUserAgents():\n",
    "    l = []\n",
    "    fp = open('data/user-agents.txt', 'r')\n",
    "\n",
    "    line  = fp.readline().strip('\\n')\n",
    "    while(line):\n",
    "        l.append(line)\n",
    "        line = fp.readline().strip('\\n')\n",
    "    fp.close()\n",
    "    \n",
    "    return l\n",
    "\n",
    "def getHeaders(base_url='https://www.google.co.in/'):\n",
    "    user_agent = user_agents[random.randint(0, len(user_agents)-1)]         \n",
    "    headers = {'user-agent': user_agent, 'connection': 'keep-alive', \n",
    "               'Accept-Encoding': 'gzip', 'referer': base_url}\n",
    "    return headers\n",
    "\n",
    "def randomSleep(minimum, maximum):\n",
    "    sleeptime =  random.randint(minimum, maximum)\n",
    "    time.sleep(sleeptime)\n",
    "\n",
    "def getHTMLData(url, base_url='', number_of_retries=3):\n",
    "    retries = 1\n",
    "    response = False\n",
    "    results = ''\n",
    "    while retries <= number_of_retries:\n",
    "        try:\n",
    "            headers = getHeaders()            \n",
    "            results = requests.get(url, headers=headers)\n",
    "            response = True\n",
    "            break\n",
    "        except:\n",
    "            retries += 1\n",
    "            randomSleep(30, 90)\n",
    "            \n",
    "            \n",
    "    randomSleep(5, 10)\n",
    "    return response, results\n",
    "\n",
    "def checkSongArtistExists():\n",
    "    if songs.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return songs.loc[((songs['song'] == row['song']) & \\\n",
    "            (songs['artist_name'] == row['artist_name']))].shape[0]\n",
    "    \n",
    "def performSearch(search_text):\n",
    "    driver.find_element_by_id('lst-ib').clear()\n",
    "    driver.find_element_by_id('lst-ib').send_keys(search_text)\n",
    "    driver.find_element_by_id('lst-ib').send_keys(Keys.RETURN)\n",
    "    randomSleep(5, 15)\n",
    "\n",
    "def getSerachKeyword(song, artist_name):\n",
    "    position = random.randint(1, 3)\n",
    "    text = 'lyrics'\n",
    "    if position == 1:\n",
    "        keyword = text + ' ' + song + ' ' + artist_name\n",
    "    if position == 2:\n",
    "        keyword = song + ' ' + text + ' ' + artist_name\n",
    "    else:\n",
    "        keyword = song + ' ' + artist_name + ' ' + text\n",
    "    return keyword\n",
    "\"\"\"    \n",
    "def getLyricsLinkFromGoogle():\n",
    "    name = url = ''\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\").find(id = 'search')\n",
    "    \n",
    "    try:\n",
    "        for link in soup.find_all(\"div\", class_=\"g\"):\n",
    "            if link.div:\n",
    "                if link.div.div:\n",
    "                    if link.div.div.h3:\n",
    "                        if link.div.div.h3.a:\n",
    "                            url = link.div.div.h3.a.get('href')\n",
    "                            name = link.div.div.h3.a.get_text()\n",
    "                            if 'azlyrics.com/lyrics/' in url:\n",
    "                                return True, url, name.strip()\n",
    "                            elif 'lyrics.az/' in url:\n",
    "                                return True, url, name.strip()\n",
    "                            elif 'genius.com/' in url:\n",
    "                                return True, url, name.strip()\n",
    "                            elif 'metrolyrics.com/' in url:\n",
    "                                return True, url, name.strip()\n",
    "                            elif 'songtexte.com/songtext/' in url:\n",
    "                                return True, url, name.strip()\n",
    "                            elif 'allthelyrics.com/lyrics/' in url:\n",
    "                                return True, url, name.strip()\n",
    "                            elif 'azlyricdb.com/lyrics/' in url:\n",
    "                                url = url + '#.W0UNGtgzZPt'\n",
    "                                return True, url, name.strip()\n",
    "    except:\n",
    "        name = url = ''\n",
    "    \n",
    "    return False, url, name\n",
    "\"\"\"\n",
    "def validateLinks(url):\n",
    "    response = False\n",
    "    for index, row in songsites.iterrows():\n",
    "        text = row['additional_text']\n",
    "        if row['site'].strip() in url:\n",
    "            response = True\n",
    "            if not pd.isna(text):\n",
    "                url = url.strip() + text.strip()\n",
    "    return response, url\n",
    "\n",
    "def getLyricsLinksFromGoogle(keyword):\n",
    "    performSearch(keyword)\n",
    "    \n",
    "    songlinks = pd.DataFrame(columns=['search_title', 'search_url'])\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\").find(id = 'search')\n",
    "    \n",
    "    idx = 0\n",
    "    for link in soup.find_all(\"div\", class_=\"g\"):\n",
    "        if link.div:\n",
    "            if link.div.div:\n",
    "                if link.div.div.h3:\n",
    "                    if link.div.div.h3.a:\n",
    "                        url = link.div.div.h3.a.get('href')\n",
    "                        name = link.div.div.h3.a.get_text()\n",
    "                        (response, url) = validateLinks(url)\n",
    "                        \n",
    "                        if response:\n",
    "                            songlinks.loc[idx] = [name, url]\n",
    "                            idx += 1\n",
    "    return songlinks\n",
    "\n",
    "def getLyticsFromAZLyrics(soup):\n",
    "    try:\n",
    "        title = soup.find_all('div', class_='col-xs-12 col-lg-8 text-center')[0] \\\n",
    "            .find_all('b')[1].text.strip()\n",
    "        lyric = soup.find_all('div', class_='col-xs-12 col-lg-8 text-center')[0] \\\n",
    "            .find_all('div')[6].text.strip()\n",
    "        response = True\n",
    "    except:\n",
    "        title = lyrics = ''\n",
    "        response = False\n",
    "    return response, title, lyric\n",
    "\n",
    "def getLyticsFromLyricsAZ(soup):\n",
    "    try:\n",
    "        title = soup.find_all('div', class_='right-column main-content lyrics-page')[0]\\\n",
    "            .div.h1.text.strip()\n",
    "        lyric = soup.find_all('div', class_='right-column main-content lyrics-page')[0]\\\n",
    "            .find_all('p', class_='lyric-text')[0].get_text()\n",
    "        response = True\n",
    "    except:\n",
    "        title = lyric = ''\n",
    "        response = False\n",
    "    return response, title, lyric\n",
    "\n",
    "def getLyticsFromGenius(soup):\n",
    "    try:\n",
    "        title = soup.find_all('div', class_='header_with_cover_art-primary_info')[0]\\\n",
    "            .h1.text.strip()\n",
    "        lyric = soup.find_all('div', class_='song_body-lyrics')[0]\\\n",
    "            .find_all('div', class_='lyrics')[0].get_text()\n",
    "        response = True\n",
    "    except:\n",
    "        title = lyric = ''\n",
    "        response = False\n",
    "    return response, title, lyric\n",
    "\n",
    "def getLyticsFromMetroLyrics(soup):\n",
    "    try:\n",
    "        title = soup.find_all('div', class_='banner-heading')[0].h1.text.strip()\n",
    "        lyric = soup.find_all('div', id='lyrics-body-text')[0].get_text()\n",
    "        response = True\n",
    "    except:\n",
    "        title = lyric = ''\n",
    "        response = False\n",
    "    return response, title, lyric\n",
    "\n",
    "def getLyticsFromSongtexte(soup):\n",
    "    try:\n",
    "        title = soup.find_all('div', class_='lyricsContainer')[0].h2.text.strip()\n",
    "        lyric = soup.find_all('div', id='lyrics')[0].get_text()\n",
    "        response = True\n",
    "    except:\n",
    "        title = lyric = ''\n",
    "        response = False\n",
    "    return response, title, lyric\n",
    "\n",
    "def getLyticsFromAllthelyrics(soup):\n",
    "    try:\n",
    "        title = soup.find_all('div', class_='clear-block')[2].h1.text.strip()\n",
    "        lyric = soup.find_all('div', class_='content-text-inner')[0].get_text().strip()\n",
    "        response = True\n",
    "    except:\n",
    "        title = lyric = ''\n",
    "        response = False\n",
    "    return response, title, lyric\n",
    "\n",
    "def getLyticsFromAZlyricdb(soup):\n",
    "    try:\n",
    "        title = soup.find_all('div', id='dl')[0].h1.text.strip()\n",
    "        lyric = soup.find_all('div', id='lrc')[0].get_text().strip()\n",
    "        response = True\n",
    "    except:\n",
    "        title = lyric = ''\n",
    "        response = False\n",
    "    return response, title, lyric\n",
    "\n",
    "def getLyrics(songlinks):\n",
    "    title = lyric = url = name = ''\n",
    "    response = False\n",
    "        \n",
    "    for index, row in songlinks.iterrows():\n",
    "        url = row['search_url']\n",
    "        name = row['search_title']\n",
    "        \n",
    "        (response, results) = getHTMLData(url, number_of_retries=1)\n",
    "        \n",
    "        if response:\n",
    "            soup = BeautifulSoup(results.text, \"html.parser\")\n",
    "\n",
    "            if 'azlyrics.com/lyrics/' in url:\n",
    "                (response, title, lyric) = getLyticsFromAZLyrics(soup)\n",
    "            elif 'lyrics.az/' in url:\n",
    "                (response, title, lyric) = getLyticsFromLyricsAZ(soup)\n",
    "            elif 'genius.com/' in url:\n",
    "                (response, title, lyric) = getLyticsFromGenius(soup)\n",
    "            elif 'metrolyrics.com/' in url:\n",
    "                (response, title, lyric) = getLyticsFromMetroLyrics(soup)\n",
    "            elif 'songtexte.com/songtext/' in url:\n",
    "                (response, title, lyric) = getLyticsFromSongtexte(soup)\n",
    "            elif 'allthelyrics.com/lyrics/' in url:\n",
    "                (response, title, lyric) = getLyticsFromAllthelyrics(soup)\n",
    "            elif 'azlyricdb.com/lyrics/' in url:\n",
    "                (response, title, lyric) = getLyticsFromAZlyricdb(soup)\n",
    "\n",
    "            if response:\n",
    "                break\n",
    "\n",
    "    return response, url, name, title, lyric\n",
    "\n",
    "print('Functions loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "bb_hot100_song = pd.read_csv('data/bb_hot100_song.csv')\n",
    "bb_hot100_song['processed'] = 0\n",
    "bb_hot100_song['search_title'] = ''\n",
    "bb_hot100_song['search_url'] = ''\n",
    "bb_hot100_song['song_title'] = ''\n",
    "bb_hot100_song['song_lyric'] = ''\n",
    "\n",
    "if Path('data/songs.csv').is_file():\n",
    "    songs = pd.read_csv('data/songs.csv', \\\n",
    "            dtype={'search_title': np.object, \\\n",
    "                   'search_url': np.object, \\\n",
    "                   'song_title': np.object, \\\n",
    "                   'song_lyric': np.object})\n",
    "else:\n",
    "    songs = pd.DataFrame(columns=['song', 'artist_name', 'processed', 'search_title', \\\n",
    "                                  'search_url', 'song_title', 'song_info', 'song_lyric'])\n",
    "\n",
    "songsites = pd.read_csv('data/songsites.csv', \\\n",
    "            dtype={'site': np.object, \\\n",
    "                   'additional_text': np.object})\n",
    "\n",
    "print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in bb_hot100_song.iterrows():\n",
    "    if checkSongArtistExists() == 0:\n",
    "        songs = songs.append(row, ignore_index=True)\n",
    "\n",
    "songs.to_csv('data/songs.csv', encoding='utf-8', index=False)\n",
    "\n",
    "print('Check and update missing songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8357 entries, 0 to 8356\n",
      "Data columns (total 7 columns):\n",
      "song            8357 non-null object\n",
      "artist_name     8357 non-null object\n",
      "processed       8357 non-null int64\n",
      "search_title    8316 non-null object\n",
      "search_url      8316 non-null object\n",
      "song_title      8316 non-null object\n",
      "song_lyric      8316 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 457.1+ KB\n"
     ]
    }
   ],
   "source": [
    "songs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiated web scraping using Selenium!\n"
     ]
    }
   ],
   "source": [
    "# Specifying incognito mode as you launch your browser[OPTIONAL]\n",
    "option = webdriver.ChromeOptions()\n",
    "option.add_argument(\"--incognito\")\n",
    "\n",
    "# Create new Instance of Chrome in incognito mode\n",
    "driver = webdriver.Chrome(executable_path='driver/chromedriver', chrome_options=option)\n",
    "driver.implicitly_wait(3)\n",
    "driver.get('http://www.google.com')\n",
    "\n",
    "print('Initiated web scraping using Selenium!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data using Google/Lyrics\n",
      "----------------\n",
      "Index:  7984 Song: Corazon  | Atrist:  Maluma X Nego do Borel\n",
      "Google:  nan\n",
      "Title:  nan\n",
      "-----------------------\n",
      "Index:  8105 Song: Up Down  | Atrist:  Morgan Wallen Featuring Florida Georgia Line\n",
      "Google:  nan\n",
      "Title:  nan\n",
      "-----------------------\n",
      "Index:  8147 Song: Guatemala  | Atrist:  Swae Lee Featuring Slim Jxmmi\n",
      "Google:  nan\n",
      "Title:  nan\n",
      "-----------------------\n",
      "Index:  8225 Song: Big Bank  | Atrist:  YG Featuring 2 Chainz, Big Sean & Nicki Minaj\n",
      "Google:  nan\n",
      "Title:  nan\n",
      "-----------------------\n",
      "Processing Done!\n"
     ]
    }
   ],
   "source": [
    "index_min, index_max = 7500, 8500\n",
    "\n",
    "user_agents = getUserAgents()\n",
    "\n",
    "print('Getting data using Google/Lyrics')\n",
    "print('----------------')\n",
    "\n",
    "tot = songs.shape[0]\n",
    "index_prev = -1\n",
    "\n",
    "for index, row in songs.iterrows():\n",
    "    if index >= index_min and index < index_max:\n",
    "        song = row['song']\n",
    "        artist_name = row['artist_name']\n",
    "        processed = row['processed']\n",
    "        search_title = row['search_title']\n",
    "        search_url = row['search_url']\n",
    "        song_title = row['song_title']\n",
    "        song_lyric = row['song_lyric']\n",
    "\n",
    "        if processed == 0:\n",
    "            keyword = getSerachKeyword(song, artist_name)\n",
    "            songlinks = getLyricsLinksFromGoogle(keyword)\n",
    "                    \n",
    "            if songlinks.shape[0] > 0:\n",
    "                (response, sr_url, sr_title, title, lyric) = getLyrics(songlinks)\n",
    "\n",
    "                if response:\n",
    "                    search_title = sr_title\n",
    "                    search_url = sr_url\n",
    "                    song_title = title\n",
    "                    song_lyric = lyric\n",
    "                    processed = 1\n",
    "\n",
    "        songs.at[index, 'processed'] = processed\n",
    "        songs.at[index, 'search_title'] = search_title\n",
    "        songs.at[index, 'search_url'] = search_url\n",
    "        songs.at[index, 'song_title'] = song_title\n",
    "        songs.at[index, 'song_lyric'] = song_lyric\n",
    "        \n",
    "        if processed == 0:\n",
    "            print('Index: ', index, 'Song:', song, ' | Atrist: ', artist_name)\n",
    "            print('Google: ', search_url)\n",
    "            print('Title: ', song_title)\n",
    "            print('-----------------------')\n",
    "    \n",
    "songs.to_csv('data/songs.csv', encoding='utf-8', index=False)\n",
    "print('Processing Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songlinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getLyrics(songlinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.to_csv('data/songs.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getLyrics('http://www.songtexte.com/songtext/marc-nelson/15-minutes-4bdb2726.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'http://www.songtexte.com/songtext/marc-nelson/15-minutes-4bdb2726.html'\n",
    "# results = getHTMLData(url)\n",
    "# soup = BeautifulSoup(results.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup\\\n",
    "#                .find_all('div', id='lyrics')[0]\\\n",
    "#                .get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup \\\n",
    "#                .find_all('div', class_='banner-heading')[0] \\\n",
    "#                .h1.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
