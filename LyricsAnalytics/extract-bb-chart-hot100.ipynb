{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules loaded!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "print('Modules loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data loaded!\n"
     ]
    }
   ],
   "source": [
    "bb_hot100_issue_data = pd.read_csv('data/bb_hot100_issue_data.csv')\n",
    "bb_hot100_song_data = pd.read_csv('data/bb_hot100_song_data.csv')\n",
    "\n",
    "print('CSV data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def getBBHot100Issues(year, number_of_retries=3):\n",
    "    issues = pd.DataFrame(columns=['year', 'issue_date', 'issue_title', 'issue_url'])\n",
    "    \n",
    "    domain = 'https://www.billboard.com'\n",
    "    url = domain + '/archive/charts/' + str(year) + '/hot-100'\n",
    "    \n",
    "    retries = 1\n",
    "    while retries <= number_of_retries:\n",
    "        try:\n",
    "            page = urllib.request.urlopen(url, data=None, context=None)\n",
    "            break\n",
    "        except:\n",
    "            retries += 1\n",
    "            time.sleep(30)\n",
    "        \n",
    "    if page:\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        idx = 0\n",
    "        for link in soup.find_all('a'):\n",
    "            if link.get('href') is not None:\n",
    "                if '/charts/hot-100/' in link.get('href'):\n",
    "                    issue_date = link.get('href')[-10:]\n",
    "                    issue_title = link.string\n",
    "                    issue_url = link.get('href')\n",
    "                    issues.loc[idx] = [year, issue_date, issue_title, issue_url]\n",
    "                    idx += 1\n",
    "        \n",
    "    time.sleep(5)\n",
    "    return issues\n",
    "\n",
    "def getBBHot100Songs(issue_date, issue_url, number_of_retries=3):\n",
    "    songs = pd.DataFrame(columns=['issue_date', 'rank', 'song', 'artist_name', 'artist_url'])\n",
    "    \n",
    "    domain = 'https://www.billboard.com'\n",
    "    url = domain + issue_url\n",
    "    \n",
    "    retries = 1\n",
    "    while retries <= number_of_retries:\n",
    "        try:\n",
    "            page = urllib.request.urlopen(url, data=None, context=None)\n",
    "            break\n",
    "        except:\n",
    "            retries += 1\n",
    "            time.sleep(30)\n",
    "\n",
    "    if page:\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        idx = 0\n",
    "        for link in soup.find_all(\"div\", class_=\"chart-row__title\"):\n",
    "            song = link.h2.text\n",
    "            rank = idx+1\n",
    "            artist_name = ''\n",
    "            artist_url = ''\n",
    "\n",
    "            if link.a:\n",
    "                artist_name = link.a.text.replace('\\n', '')\n",
    "                artist_url = link.a.get('href')\n",
    "            elif link.span:\n",
    "                artist_name = link.span.text.replace('\\n', '')\n",
    "\n",
    "            songs.loc[idx] = [issue_date, rank, song, artist_name, artist_url]\n",
    "            idx += 1\n",
    "            \n",
    "    time.sleep(5)\n",
    "    return songs\n",
    "\n",
    "print('Functions loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting issues for year:  2018\n",
      "----------------\n",
      "No issues pending to be processed\n",
      "----------------\n",
      "Processing Done!\n"
     ]
    }
   ],
   "source": [
    "drop_index = []\n",
    "year = 2018\n",
    "print('Getting issues for year: ', str(year))\n",
    "issues = getBBHot100Issues(year)\n",
    "print('----------------')\n",
    "\n",
    "for index, row in issues.iterrows():\n",
    "    if ((bb_hot100_issue_data['issue_date'] == row['issue_date'])).any():\n",
    "        drop_index.append(index)\n",
    "\n",
    "issues = issues.drop(drop_index, axis=0)\n",
    "number_of_issues = issues.shape[0]\n",
    "\n",
    "if number_of_issues > 0:\n",
    "    print('Issues yet to be processed: ', str(number_of_issues))\n",
    "    print('----------------')\n",
    "    \n",
    "    for index, row in issues.iterrows():\n",
    "        print('Processing issue: ', str(row['issue_date']))\n",
    "        songs = getBBHot100Songs(row['issue_date'], row['issue_url'])\n",
    "        bb_hot100_song_data = pd.concat([bb_hot100_song_data, songs])\n",
    "\n",
    "    bb_hot100_issue_data = pd.concat([bb_hot100_issue_data, issues])\n",
    "    print('----------------')\n",
    "else:\n",
    "    print('No issues pending to be processed')\n",
    "    print('----------------')\n",
    "\n",
    "print('Processing Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your data is up-to-date - Good!\n"
     ]
    }
   ],
   "source": [
    "if number_of_issues > 0:\n",
    "    bb_hot100_issue_data.to_csv('data/bb_hot100_issue_data.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    bb_hot100_song_data.to_csv('data/bb_hot100_song_data.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    bb_hot100_song_data[['song', 'artist_name']].drop_duplicates() \\\n",
    "        .to_csv('data/bb_hot100_song.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    bb_hot100_song_data[['artist_name']].drop_duplicates() \\\n",
    "        .to_csv('data/bb_hot100_artist.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    print('Both issues and songs exported to CSV along with summarized data!')\n",
    "else:\n",
    "    print('Your data is up-to-date - Good!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
